{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "import pyopencl.array as cl_array\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyopencl.ipython_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = cl.create_some_context()\n",
    "queue = cl.CommandQueue(ctx)\n",
    "mf = cl.mem_flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各个算子的opencl实现，这里还可以优化一下实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel -o \"-cl-fast-relaxed-math\"\n",
    "\n",
    "__kernel void Conv2D(__global const float *ift, \n",
    "                     __global float *weight, __global float *bias,\n",
    "                     __global int *output_channel, __global int *output_height, __global int *output_width,\n",
    "                     __global int *input_channel, __global int *input_height, __global int *input_width,\n",
    "                     __global int *feature_height, __global int *feature_width,\n",
    "                     __global float *oft)\n",
    "{\n",
    "    int Co = *output_channel, Ho = *output_height, Wo = *output_width;\n",
    "    int Ci = *input_channel, Hi = *input_height, Wi = *input_width;\n",
    "    int Hf = *feature_height, Wf = *feature_width;\n",
    "    int posc = get_global_id(0), posh = get_global_id(1), posw = get_global_id(2);\n",
    "    int So = Wo*Ho, Sf = Wf*Hf, Si = Wi*Hi;\n",
    "    int Vf = Sf*Ci;\n",
    "    int i = posc*(So) + (posh*Wo+posw);\n",
    "    \n",
    "    oft[i] = bias[posc];\n",
    "    for(int l = 0; l < Hf; l++) {\n",
    "        for(int m = 0; m < Wf; m++) {\n",
    "            for(int n = 0; n < Ci; n++) {\n",
    "                oft[i] += ift[(n*Si)+((posh+l)*Wi)+(posw+m)]*weight[(posc*Vf)+(n*Sf)+(l*Wf)+(m)];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel -o \"-cl-fast-relaxed-math\"\n",
    "\n",
    "__kernel void BatchNorm2D(__global const float *ift, \n",
    "        __global float *mean, __global float *std,\n",
    "        __global float *eps, __global float *weight, __global float *bias,\n",
    "        __global int *channel, __global int *height, __global int *width,\n",
    "        __global float *oft)\n",
    "{\n",
    "    int c = *channel, h = *height, w = *width;\n",
    "    int posc = get_global_id(0), posh = get_global_id(1), posw = get_global_id(2);\n",
    "    int i = posc*(w*h) + (posh*w+posw);\n",
    "    float e = *eps;\n",
    "    float res1 = ift[i] - mean[posc];\n",
    "    float res2 = sqrt(std[posc] + e);\n",
    "    float res3 = res1 / res2;\n",
    "    oft[i] = res3 * weight[posc] + bias[posc];\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel -o \"-cl-fast-relaxed-math\"\n",
    "\n",
    "__kernel void Linear(__global const float *ift, \n",
    "                     __global float *weight, __global float *bias,\n",
    "                     __global int *output_channel, __global int *input_channel,\n",
    "                     __global float *oft)\n",
    "{\n",
    "    int Co = *output_channel, Ci = *input_channel;\n",
    "    int posCo = get_global_id(0);\n",
    "    \n",
    "    oft[posCo] = bias[posCo];\n",
    "    for(int k = 0; k < Ci; k++) {\n",
    "        oft[posCo] += ift[k]*weight[posCo*Ci+k];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel -o \"-cl-fast-relaxed-math\"\n",
    "\n",
    "__kernel void MaxPool2D(__global const float *ift, \n",
    "                        __global int *size, __global int *stride,\n",
    "                        __global int *channel, \n",
    "                        __global int *input_height, __global int *input_width, \n",
    "                        __global int *output_height, __global int *output_width, \n",
    "                        __global float *oft)\n",
    "{\n",
    "    int sz = *size, sd = *stride;\n",
    "    int C = *channel, Hi = *input_height, Wi = *input_width, Ho = *output_height, Wo = *output_width;\n",
    "    int posc = get_global_id(0), posh = get_global_id(1), posw = get_global_id(2);\n",
    "    \n",
    "    int So = Ho*Wo, Si = Hi*Wi;\n",
    "    int i = (posc*(So))+(posh*Wo)+(posw);\n",
    "    int startX = posw*sd, startY = posh*sd;\n",
    "    \n",
    "    oft[i] = ift[(posc*(Si))+(startY*Wi)+startX];\n",
    "    for(int y = 0; y < sz; y++) {\n",
    "        for(int x = 0; x < sz; x++) {\n",
    "            oft[i] = max(oft[i], ift[(posc*(Si))+((startY+y)*Wi)+(startX+x)]);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel -o \"-cl-fast-relaxed-math\"\n",
    "\n",
    "__kernel void ReluD1(__global const float *ift, __global float *oft)\n",
    "{\n",
    "    int i = get_global_id(0);\n",
    "    oft[i] = max((float)0, ift[i]);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel -o \"-cl-fast-relaxed-math\"\n",
    "\n",
    "__kernel void ReluD3(__global const float *ift, __global float *oft,\n",
    "                  __global int *channel, __global int *height, __global int *width)\n",
    "{\n",
    "    int c = *channel;\n",
    "    int h = *height;\n",
    "    int w = *width;\n",
    "    int posc = get_global_id(0);\n",
    "    int posh = get_global_id(1);\n",
    "    int posw = get_global_id(2);\n",
    "    int i = posc*(w*h) + (posh*w+posw);\n",
    "    oft[i] = max((float)0, ift[i]);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 封装opencl代码，这里可以优化一下数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_numpy, kernel_weight_numpy, kernel_bias_numpy, padding = 0):\n",
    "    # 卷积前预处理，在CPU端做padding和开辟内存空间\n",
    "    input_numpy = input_numpy\n",
    "    weight_cpu = kernel_weight_numpy\n",
    "    bias_cpu = kernel_bias_numpy\n",
    "\n",
    "    Ci, Hi, Wi = input_numpy.shape\n",
    "    input_cpu = np.zeros((Ci, Hi+2*padding, Wi+2*padding)).astype(np.float32)\n",
    "    if padding > 0:\n",
    "        input_cpu[:, padding:-padding, padding:-padding] = input_numpy\n",
    "    else:\n",
    "        input_cpu = input_numpy\n",
    "\n",
    "    Ci, Hi, Wi = input_cpu.shape\n",
    "    Co, Ci, Hf, Wf = weight_cpu.shape\n",
    "    Ho, Wo = Hi - Hf + 1, Wi - Wf + 1\n",
    "    output_cpu = np.zeros((Co,Ho,Wo)).astype(np.float32)\n",
    "    # 将数据从host搬运到device\n",
    "    input_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = input_cpu)\n",
    "\n",
    "    kernel_weight_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = weight_cpu)\n",
    "    kernel_bias_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = bias_cpu)\n",
    "\n",
    "    output_channel_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Co))\n",
    "    output_height_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Ho))\n",
    "    output_width_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Wo))\n",
    "    input_channel_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Ci))\n",
    "    input_height_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Hi))\n",
    "    input_width_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Wi))\n",
    "    feature_height_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Hf))\n",
    "    feature_width_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Wf))\n",
    "\n",
    "    output_gpu = cl.Buffer(ctx, mf.WRITE_ONLY, output_cpu.nbytes)\n",
    "    # device执行\n",
    "    Conv2D(queue, output_cpu.shape, None, \n",
    "           input_gpu, \n",
    "           kernel_weight_gpu, kernel_bias_gpu,\n",
    "           output_channel_gpu, output_height_gpu, output_width_gpu,\n",
    "           input_channel_gpu, input_height_gpu, input_width_gpu,\n",
    "           feature_height_gpu, feature_width_gpu,\n",
    "           output_gpu)\n",
    "    # 将结果从device读回到host\n",
    "    cl.enqueue_copy(queue, output_cpu, output_gpu)\n",
    "    # 结果返回\n",
    "    return output_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm2d(input_numpy, eps, weight, bias):\n",
    "    # cpu端的预处理\n",
    "    mean = input_numpy.mean(axis=(1,2))\n",
    "    std = input_numpy.std(axis=(1,2))**2\n",
    "    output_cpu = np.empty_like(input_numpy)\n",
    "    # 将数据从host搬运到device\n",
    "    input_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = input_numpy)\n",
    "\n",
    "    mean_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = mean)\n",
    "    std_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = std)\n",
    "\n",
    "    eps_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(eps))\n",
    "    weight_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = weight)\n",
    "    bias_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = bias)\n",
    "\n",
    "    channel_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(input_numpy.shape[0]))\n",
    "    height_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(input_numpy.shape[1]))\n",
    "    width_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(input_numpy.shape[2]))\n",
    "\n",
    "    output_gpu = cl.Buffer(ctx, mf.WRITE_ONLY, output_cpu.nbytes)\n",
    "    # device端执行\n",
    "    BatchNorm2D(queue, input_numpy.shape, None, input_gpu, \n",
    "                mean_gpu, std_gpu, \n",
    "                eps_gpu, weight_gpu, bias_gpu, \n",
    "                channel_gpu, height_gpu, width_gpu, \n",
    "                output_gpu)\n",
    "    # 数据写回\n",
    "    cl.enqueue_copy(queue, output_cpu, output_gpu)\n",
    "    # 返回数据\n",
    "    return output_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(input_numpy):\n",
    "    output_cpu = np.empty_like(input_numpy)\n",
    "    \n",
    "    input_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = input_numpy)\n",
    "    output_gpu = cl.Buffer(ctx, mf.WRITE_ONLY, output_cpu.nbytes)\n",
    "    if len(input_numpy.shape) == 3:\n",
    "        channel_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(input_numpy.shape[0]))\n",
    "        height_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(input_numpy.shape[1]))\n",
    "        width_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(input_numpy.shape[2]))\n",
    "        \n",
    "        ReluD3(queue, input_numpy.shape, None, input_gpu, output_gpu, channel_gpu, height_gpu, width_gpu)\n",
    "    else:\n",
    "        ReluD1(queue, input_numpy.shape, None, input_gpu, output_gpu)\n",
    "        \n",
    "    cl.enqueue_copy(queue, output_cpu, output_gpu)\n",
    "    return output_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(input_numpy,size=2,stride=2):\n",
    "    # cpu端做一下padding和内存开辟\n",
    "    C, Hi, Wi = input_numpy.shape\n",
    "    Ho, Wo = int(np.floor(Hi/stride)),int(np.floor(Wi/stride))\n",
    "    row_remainder,col_remainder = Hi%stride, Wi%stride\n",
    "    Ho += int(row_remainder!=0)\n",
    "    Wo += int(col_remainder!=0)\n",
    "    input_cpu = np.zeros((C, Hi+size-row_remainder, Wi+size-col_remainder)).astype(np.float32)\n",
    "    input_cpu[:, :Hi, :Wi] = input_numpy\n",
    "\n",
    "    C, Hi, Wi = input_cpu.shape\n",
    "\n",
    "    output_cpu = np.zeros((C,Ho,Wo)).astype(np.float32)\n",
    "    # 从host搬运数据到device\n",
    "    input_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = input_cpu)\n",
    "\n",
    "    size_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(size))\n",
    "    stride_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(stride))\n",
    "\n",
    "    channel_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(C))\n",
    "    input_height_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Hi))\n",
    "    input_width_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Wi))\n",
    "    output_height_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Ho))\n",
    "    output_width_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Wo))\n",
    "\n",
    "    output_gpu = cl.Buffer(ctx, mf.WRITE_ONLY, output_cpu.nbytes)\n",
    "    # device执行\n",
    "    MaxPool2D(queue, output_cpu.shape, None, \n",
    "               input_gpu, \n",
    "               size_gpu, stride_gpu,\n",
    "               channel_gpu,\n",
    "               input_height_gpu, input_width_gpu,\n",
    "               output_height_gpu, output_width_gpu,\n",
    "               output_gpu)\n",
    "    # 数据写回\n",
    "    cl.enqueue_copy(queue, output_cpu, output_gpu)\n",
    "    # 返回结果\n",
    "    return output_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(input_numpy, weight_numpy, bias_numpy):\n",
    "    # cpu端简单处理\n",
    "    input_cpu = input_numpy\n",
    "    weight_cpu = weight_numpy\n",
    "    bias_cpu = bias_numpy\n",
    "\n",
    "    Co, Ci = weight_cpu.shape\n",
    "\n",
    "    output_cpu = np.zeros((Co,)).astype(np.float32)\n",
    "    # 将数据从host搬运到device\n",
    "    input_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = input_cpu)\n",
    "\n",
    "    weight_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = weight_cpu)\n",
    "    bias_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = bias_cpu)\n",
    "\n",
    "    output_channel_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Co))\n",
    "    input_channel_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(Ci))\n",
    "\n",
    "    output_gpu = cl.Buffer(ctx, mf.WRITE_ONLY, output_cpu.nbytes)\n",
    "    # device执行\n",
    "    Linear(queue, output_cpu.shape, None, \n",
    "               input_gpu, \n",
    "               weight_gpu, bias_gpu,\n",
    "               output_channel_gpu, input_channel_gpu,\n",
    "               output_gpu)\n",
    "    # 数据写回\n",
    "    cl.enqueue_copy(queue, output_cpu, output_gpu)\n",
    "    # 返回数据\n",
    "    return output_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载pytorch的模型获取参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1 ),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fclayer = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84,num_classes)\n",
    "        ) \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x=x.view(-1, 16*5*5)\n",
    "        x=self.fclayer(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet(10)\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opencl的lenet推理代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencl_LeNet(model, input_numpy):\n",
    "    layer1_Conv2d = model.layer1[0]\n",
    "    layer1_BatchNorm2d = model.layer1[1]\n",
    "    layer1_ReLU = model.layer1[2]\n",
    "    layer1_MaxPool2d = model.layer1[3]\n",
    "\n",
    "    layer2_Conv2d = model.layer2[0]\n",
    "    layer2_BatchNorm2d = model.layer2[1]\n",
    "    layer2_ReLU = model.layer2[2]\n",
    "    layer2_MaxPool2d = model.layer2[3]\n",
    "\n",
    "    fclayer_Linear_1 = model.fclayer[0]\n",
    "    fclayer_ReLU_1 = model.fclayer[1]\n",
    "    fclayer_Linear_2 = model.fclayer[2]\n",
    "    fclayer_ReLU_2 = model.fclayer[3]\n",
    "    fclayer_Linear_3 = model.fclayer[4]\n",
    "\n",
    "    \n",
    "    \n",
    "    layer1_Conv2d_numpy_out = conv2d(input_numpy, layer1_Conv2d.weight.detach().numpy(), layer1_Conv2d.bias.detach().numpy(), padding = 2)\n",
    "    layer1_BatchNorm2d_numpy_out = batchnorm2d(layer1_Conv2d_numpy_out, layer1_BatchNorm2d.eps, layer1_BatchNorm2d.weight.detach().numpy(), layer1_BatchNorm2d.bias.detach().numpy())\n",
    "    layer1_ReLU_numpy_out = relu(layer1_BatchNorm2d_numpy_out)\n",
    "    layer1_MaxPool2d_numpy_out = maxpool2d(layer1_ReLU_numpy_out, 2)\n",
    "\n",
    "    layer2_Conv2d_numpy_out = conv2d(layer1_MaxPool2d_numpy_out, layer2_Conv2d.weight.detach().numpy(), layer2_Conv2d.bias.detach().numpy(), padding = 0)\n",
    "    layer2_BatchNorm2d_numpy_out = batchnorm2d(layer2_Conv2d_numpy_out, layer2_BatchNorm2d.eps, layer2_BatchNorm2d.weight.detach().numpy(), layer2_BatchNorm2d.bias.detach().numpy())\n",
    "    layer2_ReLU_numpy_out = relu(layer2_BatchNorm2d_numpy_out)\n",
    "    layer2_MaxPool2d_numpy_out = maxpool2d(layer2_ReLU_numpy_out, 2)\n",
    "\n",
    "    layer2_MaxPool2d_numpy_out = layer2_MaxPool2d_numpy_out.reshape(-1, 16*5*5)\n",
    "\n",
    "    fclayer_Linear_1_numpy_out = linear(layer2_MaxPool2d_numpy_out, fclayer_Linear_1.weight.detach().numpy(), fclayer_Linear_1.bias.detach().numpy())\n",
    "    fclayer_ReLU_1_numpy_out = relu(fclayer_Linear_1_numpy_out)\n",
    "    fclayer_Linear_2_numpy_out = linear(fclayer_ReLU_1_numpy_out, fclayer_Linear_2.weight.detach().numpy(), fclayer_Linear_2.bias.detach().numpy())\n",
    "    fclayer_ReLU_2_numpy_out = relu(fclayer_Linear_2_numpy_out)\n",
    "    fclayer_Linear_3_numpy_out = linear(fclayer_ReLU_2_numpy_out, fclayer_Linear_3.weight.detach().numpy(), fclayer_Linear_3.bias.detach().numpy())\n",
    "\n",
    "    return fclayer_Linear_3_numpy_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1,1,28,28)\n",
    "input_numpy = input.numpy()[0,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opencl测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.917871475219727 ms\n",
      "[ -9.883773    -2.906955    -0.44889766  -4.6636806    4.7284713\n",
      "  -3.7774043  -11.212778     8.368049    -8.964938    -4.5382714 ]\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "out = opencl_LeNet(model,input_numpy)\n",
    "time2 = time.time()\n",
    "print('{} ms'.format(1000*(time2-time1)))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch的cpu测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9909610748291016 ms\n",
      "[[ -9.883716    -2.9068499   -0.44886065  -4.663604     4.728376\n",
      "   -3.7773778  -11.212698     8.367999    -8.9648485   -4.5381927 ]]\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "out = model(input)\n",
    "time2 = time.time()\n",
    "print('{} ms'.format(1000*(time2-time1)))\n",
    "print(out.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
