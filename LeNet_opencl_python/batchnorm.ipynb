{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "import pyopencl.array as cl_array\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyopencl.ipython_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = cl.create_some_context()\n",
    "queue = cl.CommandQueue(ctx)\n",
    "mf = cl.mem_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1 ),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fclayer = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84,num_classes)\n",
    "        ) \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x=x.view(-1, 16*5*5)\n",
    "        x=self.fclayer(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet(10)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "layer1_Conv2d = model.layer1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 1, 5, 5]), torch.Size([6]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1_Conv2d.weight.shape,layer1_Conv2d.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_numpy, kernel_weight_numpy, kernel_bias_numpy, padding = 0):\n",
    "    B, Ci, Hi, Wi = input_numpy.shape\n",
    "    input_pad_numpy = torch.zeros(B, Ci, Hi+2*padding, Wi+2*padding)\n",
    "    if padding > 0:\n",
    "        input_pad_numpy[:, :, padding:-padding, padding:-padding] = input_numpy\n",
    "    else:\n",
    "        input_pad_numpy = input_numpy\n",
    "    B, Ci, Hi, Wi = input_pad_numpy.shape\n",
    "    Co, Ci, Hf, Wf = kernel_weight_numpy.shape\n",
    "    Ho, Wo = Hi - Hf + 1, Wi - Wf + 1\n",
    "    # conv2d weight 7 loop\n",
    "    out = np.zeros((B,Co,Ho,Wo))\n",
    "    for b in range(B):\n",
    "        for i in range(Ho):\n",
    "            for j in range(Wo):\n",
    "                for k in range(Co):\n",
    "                    for l in range(Hf):\n",
    "                        for m in range(Wf):\n",
    "                            for n in range(Ci):\n",
    "                                out[b,k,i,j] += input_pad_numpy[b,n,i+l,j+m]*kernel_weight_numpy[k,n,l,m]\n",
    "    for b in range(B):\n",
    "        for i in range(Ho):\n",
    "            for j in range(Wo):\n",
    "                for k in range(Co):\n",
    "                    out[b,k,i,j] += kernel_bias_numpy[k]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(1,1,28,28)\n",
    "\n",
    "input = 2.0 * (np.random.rand(4,4,4).astype(np.float32) - 0.5)\n",
    "weight = layer1_BatchNorm2d.weight.detach().numpy()\n",
    "bias = layer1_BatchNorm2d.bias.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = input)\n",
    "\n",
    "mean_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = mean)\n",
    "std_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = std)\n",
    "\n",
    "eps_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(eps))\n",
    "weight_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = weight)\n",
    "bias_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = bias)\n",
    "\n",
    "channel_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(input.shape[0]))\n",
    "height_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(input.shape[1]))\n",
    "width_gpu = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = np.int32(input.shape[2]))\n",
    "\n",
    "output_gpu = cl.Buffer(ctx, mf.WRITE_ONLY, input.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cl_kernel -o \"-cl-fast-relaxed-math\"\n",
    "\n",
    "__kernel void BatchNorm2D(__global const float *ift, \n",
    "        __global float *mean, __global float *std,\n",
    "        __global float *eps, __global float *weight, __global float *bias,\n",
    "        __global int *channel, __global int *height, __global int *width,\n",
    "        __global float *oft)\n",
    "{\n",
    "    int c = *channel, h = *height, w = *width;\n",
    "    int posc = get_global_id(0), posh = get_global_id(1), posw = get_global_id(2);\n",
    "    int i = posc*(w*h) + (posh*w+posw);\n",
    "    float e = *eps;\n",
    "    float res1 = ift[i] - mean[posc];\n",
    "    float res2 = sqrt(std[posc] + e);\n",
    "    float res3 = res1 / res2;\n",
    "    oft[i] = res3 * weight[posc] + bias[posc];\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl._cl.Event at 0x2c6a0bce3a8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BatchNorm2D(queue, input.shape, None, input_gpu, mean_gpu, std_gpu, eps_gpu, weight_gpu, bias_gpu, channel_gpu, height_gpu, width_gpu, output_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl._cl.NannyEvent at 0x2c6a0bce8e8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.empty_like(input)\n",
    "cl.enqueue_copy(queue, result, output_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.12930298, -0.54422164, -0.5404496 ,  0.56641155],\n",
       "        [ 0.32734716, -0.04603638, -0.27638122,  0.12862907],\n",
       "        [ 0.20284243, -0.24211188, -0.14477941, -0.3558718 ],\n",
       "        [ 0.48549154, -0.09393339, -0.05353037, -0.36649898]],\n",
       "\n",
       "       [[ 1.0770097 , -0.81170666,  0.5653544 , -1.1986618 ],\n",
       "        [-0.01809002, -0.12676686,  0.05970845, -0.7814994 ],\n",
       "        [ 1.0996418 , -0.02657328, -1.268249  , -1.7871226 ],\n",
       "        [ 1.3546574 ,  0.05242227, -0.02483744, -0.40442872]],\n",
       "\n",
       "       [[ 0.2779464 , -1.314091  , -0.18237348, -1.2827958 ],\n",
       "        [-1.0967008 , -0.7878097 ,  0.36083177, -0.4661757 ],\n",
       "        [-0.12390527,  0.06764246, -0.55066997, -1.2130908 ],\n",
       "        [-0.5317401 ,  0.2721272 ,  0.1377413 ,  0.6034245 ]],\n",
       "\n",
       "       [[-0.53256226, -0.6765078 ,  0.5455077 , -1.0082785 ],\n",
       "        [ 0.945174  , -0.27320042, -0.51388526,  1.3549521 ],\n",
       "        [ 0.37321118,  0.32849908,  0.76314795, -0.9714877 ],\n",
       "        [-0.8785274 ,  0.19135866,  1.6811198 , -0.9413318 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.12929948, -0.5442121 , -0.54044013,  0.56639959],\n",
       "        [ 0.32733981, -0.04603649, -0.27637688,  0.12862558],\n",
       "        [ 0.2028375 , -0.24210819, -0.14477761, -0.35586592],\n",
       "        [ 0.48548119, -0.09393256, -0.05353033, -0.36649286]],\n",
       "\n",
       "       [[ 1.07698299, -0.81169194,  0.56533896, -1.19863864],\n",
       "        [-0.01809269, -0.12676716,  0.05970407, -0.78148535],\n",
       "        [ 1.09961462, -0.02657576, -1.26822428, -1.78708647],\n",
       "        [ 1.35462465,  0.05241806, -0.02483996, -0.40442291]],\n",
       "\n",
       "       [[ 0.27793692, -1.31407694, -0.18237617, -1.28278217],\n",
       "        [-1.09669   , -0.78780346,  0.36082103, -0.46617419],\n",
       "        [-0.12390883,  0.06763607, -0.55066722, -1.21307823],\n",
       "        [-0.53173765,  0.27211785,  0.13773388,  0.60341025]],\n",
       "\n",
       "       [[-0.53255353, -0.67649676,  0.54549953, -1.00826225],\n",
       "        [ 0.94515944, -0.27319575, -0.51387681,  1.35493121],\n",
       "        [ 0.37320569,  0.32849431,  0.76313634, -0.97147209],\n",
       "        [-0.87851317,  0.19135603,  1.68109375, -0.94131665]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchnorm2d(input,eps,weight,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
